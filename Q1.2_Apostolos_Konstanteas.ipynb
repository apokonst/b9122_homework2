{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f5319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed url: https://www.europarl.europa.eu/news/en/press-room\n",
      "Generated 10 text files with the HTML code of press releases covering the plenary sessions and containing the word crisis\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "seed_url = \"https://www.europarl.europa.eu/news/en/press-room\"\n",
    "word = \"crisis\"\n",
    "searching_text = \"Plenary session\"\n",
    "searching_text2 = \"Press Releases\"\n",
    "min_releases = 10\n",
    "counter = 0\n",
    "urls = [seed_url]    \n",
    "seen = [seed_url]\n",
    "release_list = []\n",
    "print(\"Seed url: \"+seed_url)\n",
    "while len(urls) > 0 and counter < min_releases:\n",
    "    try:\n",
    "        curr_url=urls.pop(0)\n",
    "        req = urllib.request.Request(curr_url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "    except:\n",
    "        continue    \n",
    "    soup = BeautifulSoup(webpage) \n",
    "    found_pressrelease = False\n",
    "    found_plenarysession = False\n",
    "    for tag in soup.find_all(\"span\", class_=\"ep_name\"):\n",
    "        if (tag.text == searching_text and word in soup.text): found_plenarysession = True    #found the text \"Plenary session\" next to tag \"span\" and class \"ep_name\" and the word \"crisis\" in the URL text\n",
    "        if tag.text == searching_text2: found_pressrelease = True   #Ensure that it is a press release: Press releases have the text \"Press Releases\" next to tag \"span\" and class \"ep_name\"\n",
    "        if found_pressrelease and found_plenarysession:\n",
    "            counter += 1\n",
    "            release_list.append(curr_url)\n",
    "            break\n",
    "    if counter == min_releases: break\n",
    "    for tag in soup.find_all('a', href = True):\n",
    "        childUrl = tag['href']\n",
    "        joinedUrl = urllib.parse.urljoin(seed_url, childUrl)\n",
    "        if seed_url in joinedUrl and joinedUrl not in seen:\n",
    "            urls.append(joinedUrl)\n",
    "            seen.append(joinedUrl)\n",
    "print (\"Generated %d text files with the HTML code of press releases covering the plenary sessions and containing the word %s\" %(counter,word))\n",
    "for i in range(len(release_list)):\n",
    "    urllib.request.urlretrieve(release_list[i], \"2_\"+str(i+1)+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ffb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
